version: 0.2

env:
  variables:
    RAY_TOOLKIT_VERSION: '1.1.0'
    RAY_TF_FRAMEWORK_VERSION: '2.1.0'
    RAY_TORCH_FRAMEWORK_VERSION: '1.5.0'
    CPU_INSTANCE_TYPE: 'ml.c4.xlarge'
    GPU_INSTANCE_TYPE: 'ml.p2.xlarge'
    PY_VERSION: '36'
    BASE_ECR_REPO: 'sagemaker-rl-ray-container'    # previous images repo for layer cache, same name as pro image repo
    PREPROD_ECR_REPO: 'sagemaker-test'
    PROD_ECR_REPO: 'sagemaker-rl-ray-container'
    GITHUB_REPO: 'sagemaker-rl-container'
    FRAMEWORK_BASE_IMAGE_ACCOUNT: '763104351884'     # base image account(tf/mxnet images) required for building rl container images
    SETUP_FILE: 'setup_cmds.sh'
    SETUP_CMDS: '#!/bin/bash\npip install --upgrade pip\npip install -U -e .'


phases:
  pre_build:
    commands:
      - start-dockerd
      - |
        ACCOUNT=$(aws sts get-caller-identity --query 'Account' --output text)
        BASE_IMAGE="$ACCOUNT.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$BASE_ECR_REPO"
        PREPROD_IMAGE="$ACCOUNT.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$PREPROD_ECR_REPO"
        PROD_IMAGE="$ACCOUNT.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$PROD_ECR_REPO"
        # PR_NUM=$(echo $CODEBUILD_SOURCE_VERSION | grep -o '[0-9]\+')
      # keep ssh connection alive when communicating with remote ec2 server during integ test
      # largest connection idle time allowed: 10 seconds * 300 attempts = 50 minutes
      - |
        echo '  ServerAliveInterval 10' >> ~/.ssh/config
        echo '  ServerAliveCountMax 300' >> ~/.ssh/config
  build:
    commands:
      # install
      - echo "install"
      - pip3 install -U -e .
      # Update awscli for compatibility with the latest botocore version that breaks it
      # https://github.com/boto/boto3/issues/2596
      - pip3 install --upgrade awscli

      # launch remote gpu instance only in region us-west-2
      - |
        if [ "$AWS_DEFAULT_REGION" = "us-west-2" ]; then
          echo "launch remote gpu instance"
          prefix='ml.'
          instance_type=${GPU_INSTANCE_TYPE#"$prefix"}
          create-key-pair
          launch-ec2-instance --instance-type $instance_type --ami-name dlami-ubuntu
        else
          echo "skipping launch remote gpu instance"
        fi

      - $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids $FRAMEWORK_BASE_IMAGE_ACCOUNT)
      - |
        TF_IMAGE="$FRAMEWORK_BASE_IMAGE_ACCOUNT.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/tensorflow-training"
        TORCH_IMAGE="$FRAMEWORK_BASE_IMAGE_ACCOUNT.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/pytorch-training"
        BUILD_ID="$(echo $CODEBUILD_BUILD_ID | sed -e 's/:/-/g')"

      # pull torch cpu base images
      - echo "pull torch cpu base images"
      - |
        RAY_TORCH_CPU_BASE_TAG="$RAY_TORCH_FRAMEWORK_VERSION-cpu-py$PY_VERSION-ubuntu16.04"
        docker pull $TORCH_IMAGE:$RAY_TORCH_CPU_BASE_TAG

      # build ray torch preprod cpu images
      - echo "build ray torch preprod cpu images"
      - |
        RAY_TORCH_CPU_TAG="ray-$RAY_TOOLKIT_VERSION-torch-cpu-py$PY_VERSION"
        RAY_TORCH_CPU_TAG_BUILD_ID="ray-$RAY_TOOLKIT_VERSION-torch-cpu-py$PY_VERSION-$BUILD_ID"

        echo "pulling previous_image $BASE_IMAGE:$RAY_TORCH_CPU_TAG for layer cache..."
        $(aws ecr get-login --registry-ids $ACCOUNT --no-include-email --region $AWS_DEFAULT_REGION)
        docker pull $BASE_IMAGE:$RAY_TORCH_CPU_TAG
        docker build --cache-from $BASE_IMAGE:$RAY_TORCH_CPU_TAG \
                     -t $PREPROD_IMAGE:$RAY_TORCH_CPU_TAG_BUILD_ID \
                     -f ray/docker/$RAY_TOOLKIT_VERSION/Dockerfile.torch \
                     --build-arg processor=cpu \
                     --build-arg suffix=ubuntu16.04 \
                     --build-arg region=$AWS_DEFAULT_REGION .

      # push ray torch preprod cpu images to ecr
      - echo "push ray torch preprod cpu images to ecr"
      - |
        $(aws ecr get-login --registry-ids $ACCOUNT --no-include-email --region $AWS_DEFAULT_REGION)
        docker push $PREPROD_IMAGE:$RAY_TORCH_CPU_TAG_BUILD_ID

      # publish cpu and gpu image to prod ecr repo if this is release build 
      - |
        if is-release-build; then
          
          $(aws ecr get-login --registry-ids $ACCOUNT --no-include-email --region $AWS_DEFAULT_REGION)

          #docker rmi --force $PROD_IMAGE:$RAY_TORCH_CPU_TAG
          aws ecr batch-delete-image --repository-name $PROD_ECR_REPO --region $AWS_DEFAULT_REGION --image-ids imageTag=$RAY_TORCH_CPU_TAG
          docker tag $PREPROD_IMAGE:$RAY_TORCH_CPU_TAG_BUILD_ID $PROD_IMAGE:$RAY_TORCH_CPU_TAG
          docker push $PROD_IMAGE:$RAY_TORCH_CPU_TAG

        else
          echo "skipping publishing new image to production repo"
        fi

    finally:
      # only shut down remote gpu instance if in us-west-2
      - |
        if [ "$AWS_DEFAULT_REGION" = "us-west-2" ]; then
          echo "cleanup remote gpu instance"
          cleanup-gpu-instances
          cleanup-key-pairs
        else
          echo "No remote gpu instance to cleanup"
        fi

      # remove ecr image
      - |
        aws ecr batch-delete-image --repository-name $PREPROD_ECR_REPO --region $AWS_DEFAULT_REGION --image-ids imageTag=$RAY_TORCH_CPU_TAG_BUILD_ID
